{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# QuantDL Tutorial\n",
    "\n",
    "A comprehensive guide to using QuantDL for alpha research.\n",
    "\n",
    "**Contents:**\n",
    "1. Setup & Configuration\n",
    "2. Data Fetching (Daily Prices, Fundamentals, Metrics)\n",
    "3. Element-wise Operators (15 arithmetic + 11 logical)\n",
    "4. Time-Series Operators (26 operators)\n",
    "5. Cross-Sectional Operators (6 operators)\n",
    "6. Group Operators (6 operators)\n",
    "7. Vector & Transformational Operators (4 operators)\n",
    "8. Alpha Factor Examples\n",
    "9. Summary (68 operators total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (for AWS credentials)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import quantdl\n",
    "from quantdl import QuantDLClient\n",
    "from quantdl.operators import (\n",
    "    # Time-series (basic)\n",
    "    ts_mean, ts_sum, ts_std, ts_min, ts_max, ts_delta, ts_delay,\n",
    "    # Time-series (rolling)\n",
    "    ts_product, ts_count_nans, ts_zscore, ts_scale, ts_av_diff, ts_step,\n",
    "    # Time-series (arg)\n",
    "    ts_arg_max, ts_arg_min,\n",
    "    # Time-series (lookback)\n",
    "    ts_backfill, kth_element, last_diff_value, days_from_last_change,\n",
    "    # Time-series (stateful)\n",
    "    hump, ts_decay_linear, ts_rank,\n",
    "    # Time-series (two-variable)\n",
    "    ts_corr, ts_covariance, ts_quantile, ts_regression,\n",
    "    # Cross-sectional\n",
    "    rank, zscore, normalize, scale, quantile, winsorize,\n",
    "    # Group operators\n",
    "    group_rank, group_zscore, group_scale, group_neutralize, group_mean, group_backfill,\n",
    "    # Vector operators\n",
    "    vec_avg, vec_sum,\n",
    "    # Arithmetic operators\n",
    "    add, subtract, multiply, divide, inverse, log, power, signed_power, sqrt, sign, reverse, densify,\n",
    "    # Logical operators\n",
    "    and_, or_, not_, if_else, is_nan, lt, le, gt, ge, eq, ne,\n",
    "    # Transformational operators\n",
    "    bucket, trade_when,\n",
    ")\n",
    "# Note: abs, max, min shadow builtins, import with alias\n",
    "from quantdl.operators import abs as ops_abs, max as ops_max, min as ops_min\n",
    "\n",
    "import polars as pl\n",
    "from datetime import date\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Allow nested event loops in Jupyter\n",
    "\n",
    "print(f\"QuantDL version: {__import__('quantdl').__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QuantDL client\n",
    "# This connects to the us-equity-datalake S3 bucket\n",
    "client = QuantDLClient()\n",
    "print(\"Client initialized - connected to S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Fetching\n",
    "\n",
    "QuantDL fetches data from S3 and returns **wide tables** (rows = dates, columns = symbols).\n",
    "\n",
    "**Available data:**\n",
    "- `ticks()`: Daily OHLCV price data\n",
    "- `fundamentals()`: SEC filing data (revenue, net income, etc.)\n",
    "- `metrics()`: Derived metrics (PE ratio, ROE, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### 2.1 Security Resolution\n",
    "\n",
    "Resolve symbols, CIKs, or security IDs to `SecurityInfo` with point-in-time accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve single symbol\n",
    "info = client.resolve(\"IBM\")\n",
    "if info:\n",
    "    print(f\"Symbol: {info.symbol}\")\n",
    "    print(f\"Security ID: {info.security_id}\")\n",
    "    print(f\"Company: {info.company}\")\n",
    "    print(f\"CIK: {info.cik}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-in-time resolution - important for ticker changes\n",
    "# META was called FB before 2022\n",
    "print(\"META today:\", client.resolve(\"META\"))\n",
    "print(\"META in 2020:\", client.resolve(\"META\", as_of=date(2020, 1, 1)))\n",
    "print(\"FB in 2020:\", client.resolve(\"FB\", as_of=date(2020, 1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 2.2 Daily Price Data\n",
    "\n",
    "Fetch OHLCV data as wide tables. We use symbols with reliable data coverage in 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbols with good S3 data coverage in 2024\n",
    "# These were verified to have 100+ trading days in 2024 H1\n",
    "symbols = [\"IBM\", \"TXN\", \"NOW\", \"BMY\", \"LMT\", \"META\", \"JNJ\", \"GD\", \"SO\", \"NEE\"]\n",
    "\n",
    "# Fetch daily close prices\n",
    "prices = client.ticks(\n",
    "    symbols,\n",
    "    field=\"close\",\n",
    "    start=\"2024-01-01\",\n",
    "    end=\"2024-06-30\"\n",
    ")\n",
    "print(f\"Shape: {prices.shape}\")\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch volume data (for correlation examples later)\n",
    "volume = client.ticks(\n",
    "    symbols,\n",
    "    field=\"volume\",\n",
    "    start=\"2024-01-01\",\n",
    "    end=\"2024-06-30\"\n",
    ")\n",
    "print(f\"Volume shape: {volume.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "print(\"Price data tail:\")\n",
    "print(prices.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### 2.3 Fundamentals Data\n",
    "\n",
    "Fetch SEC filing fundamentals. Available concepts include:\n",
    "- `rev`: Revenue\n",
    "- `net_inc`: Net Income\n",
    "- `ta`: Total Assets\n",
    "- `tl`: Total Liabilities\n",
    "- And more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch revenue data (quarterly filings)\n",
    "revenue = client.fundamentals([\"IBM\", \"JNJ\"], concept=\"rev\", start=\"2022-01-01\", end=\"2024-12-31\")\n",
    "print(\"Revenue data (quarterly):\")\n",
    "print(revenue.drop_nulls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch net income\n",
    "net_income = client.fundamentals([\"IBM\", \"JNJ\"], concept=\"net_inc\", start=\"2022-01-01\", end=\"2024-12-31\")\n",
    "print(\"Net Income data:\")\n",
    "print(net_income.drop_nulls())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 2.4 Derived Metrics\n",
    "\n",
    "Fetch pre-computed metrics (PE ratio, ROE, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch PE ratio (if available)\n",
    "try:\n",
    "    pe = client.metrics([\"IBM\", \"JNJ\"], metric=\"pe_ratio\", start=\"2022-01-01\", end=\"2024-12-31\")\n",
    "    print(\"PE Ratio:\")\n",
    "    print(pe.drop_nulls())\n",
    "except Exception as e:\n",
    "    print(f\"Metrics not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Element-wise Operators\n",
    "\n",
    "Element-wise operators transform values at each cell independently.\n",
    "\n",
    "**When to use:**\n",
    "- Arithmetic: Build composite features (returns, ratios, signals)\n",
    "- Logical: Conditional alpha logic (filters, masks, branching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### 3.1 Arithmetic Operators (15 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `abs` | Absolute value |\n",
    "| `add` | Element-wise addition (variadic) |\n",
    "| `subtract` | Element-wise subtraction |\n",
    "| `multiply` | Element-wise multiplication (variadic) |\n",
    "| `divide` | Safe division (null on div-by-zero) |\n",
    "| `inverse` | 1/x (null on zero) |\n",
    "| `log` | Natural log (null on <=0) |\n",
    "| `max` | Element-wise max across DataFrames |\n",
    "| `min` | Element-wise min across DataFrames |\n",
    "| `power` | x^y |\n",
    "| `signed_power` | sign(x) * |x|^y |\n",
    "| `sqrt` | Square root (null on negative) |\n",
    "| `sign` | Sign function (-1, 0, 1) |\n",
    "| `reverse` | Negation (-x) |\n",
    "| `densify` | Remap unique values to 0..n-1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: column names for later use\n",
    "date_col = prices.columns[0]\n",
    "value_cols = prices.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs: Absolute value\n",
    "daily_change = ts_delta(prices, 1)\n",
    "abs_change = ops_abs(daily_change)\n",
    "print(\"Absolute daily change:\")\n",
    "print(abs_change.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add: Variadic addition (sum multiple DataFrames)\n",
    "# Example: combine price and volume signals\n",
    "price_signal = ts_zscore(prices, 20)\n",
    "vol_signal = ts_zscore(volume, 20)\n",
    "combined = add(price_signal, vol_signal)  # Can add more: add(a, b, c, d)\n",
    "print(\"Combined signal (price zscore + volume zscore):\")\n",
    "print(combined.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract: Element-wise subtraction\n",
    "price_momentum = ts_delta(prices, 5)\n",
    "price_momentum_10 = ts_delta(prices, 10)\n",
    "momentum_diff = subtract(price_momentum, price_momentum_10)\n",
    "print(\"Momentum spread (5d - 10d):\")\n",
    "print(momentum_diff.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply: Variadic multiplication\n",
    "# Example: volume-weighted price change\n",
    "weighted = multiply(daily_change, volume)\n",
    "print(\"Volume-weighted price change:\")\n",
    "print(weighted.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide: Safe division (handles div-by-zero as null)\n",
    "lagged_prices = ts_delay(prices, 1)\n",
    "daily_return = divide(daily_change, lagged_prices)  # (P_t - P_{t-1}) / P_{t-1}\n",
    "print(\"Daily returns (safe division):\")\n",
    "print(daily_return.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse: 1/x with null handling\n",
    "inv_prices = inverse(prices)\n",
    "print(\"Inverse of prices (1/price):\")\n",
    "print(inv_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log: Natural log (null for <=0 values)\n",
    "log_prices = log(prices)\n",
    "print(\"Log prices (for log-returns):\")\n",
    "print(log_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max/min: Element-wise max/min across DataFrames\n",
    "ma_5 = ts_mean(prices, 5)\n",
    "ma_20 = ts_mean(prices, 20)\n",
    "ma_upper = ops_max(ma_5, ma_20)  # Higher of 5d and 20d MA\n",
    "ma_lower = ops_min(ma_5, ma_20)  # Lower of 5d and 20d MA\n",
    "print(\"Upper envelope (max of MA5, MA20):\")\n",
    "print(ma_upper.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power: x^y element-wise\n",
    "# Create exponent DataFrame (constant 2.0 for squaring)\n",
    "exponent = prices.select(pl.col(date_col), *[pl.lit(2.0).alias(c) for c in value_cols])\n",
    "squared = power(prices, exponent)\n",
    "print(\"Prices squared:\")\n",
    "print(squared.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signed_power: sign(x) * |x|^y - preserves sign\n",
    "# Useful for non-linear transformations that preserve direction\n",
    "returns = ts_delta(log_prices, 1)\n",
    "exp_half = prices.select(pl.col(date_col), *[pl.lit(0.5).alias(c) for c in value_cols])\n",
    "sqrt_returns = signed_power(returns, exp_half)\n",
    "print(\"Signed sqrt of returns (preserves direction):\")\n",
    "print(sqrt_returns.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrt: Square root (null for negative)\n",
    "sqrt_prices = sqrt(prices)\n",
    "print(\"Sqrt of prices:\")\n",
    "print(sqrt_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign: Returns -1, 0, or 1\n",
    "sign_change = sign(daily_change)\n",
    "print(\"Sign of daily change:\")\n",
    "print(sign_change.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse: Negation (-x)\n",
    "neg_momentum = reverse(price_momentum)\n",
    "print(\"Negative momentum (for mean reversion):\")\n",
    "print(neg_momentum.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densify: Remap unique values to consecutive integers per row\n",
    "# Useful for categorical encoding\n",
    "ranked = rank(prices)\n",
    "bucketed = bucket(ranked, range_spec=\"0,1,0.2\")  # 5 buckets\n",
    "dense = densify(bucketed)\n",
    "print(\"Densified bucket indices:\")\n",
    "print(dense.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "### 3.2 Logical Operators (11 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `and_` | Logical AND |\n",
    "| `or_` | Logical OR |\n",
    "| `not_` | Logical NOT |\n",
    "| `if_else` | Conditional selection |\n",
    "| `is_nan` | Detect NaN/null |\n",
    "| `lt` | Less than (<) |\n",
    "| `le` | Less than or equal (<=) |\n",
    "| `gt` | Greater than (>) |\n",
    "| `ge` | Greater than or equal (>=) |\n",
    "| `eq` | Equal (==) |\n",
    "| `ne` | Not equal (!=) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison operators with scalar\n",
    "# gt: Greater than\n",
    "above_ma = gt(prices, ma_20)  # Price > 20-day MA\n",
    "print(\"Price above 20-day MA (True/False):\")\n",
    "print(above_ma.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lt, le, ge: Other comparisons\n",
    "below_ma = lt(prices, ma_20)  # Price < MA\n",
    "at_or_above = ge(prices, ma_20)  # Price >= MA\n",
    "print(\"Price below MA:\")\n",
    "print(below_ma.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eq, ne: Equality comparisons (useful for categorical data)\n",
    "# Compare with scalar\n",
    "is_positive = gt(daily_change, 0)  # Up day\n",
    "is_negative = lt(daily_change, 0)  # Down day\n",
    "print(\"Is up day:\")\n",
    "print(is_positive.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and_: Logical AND\n",
    "# Buy signal: price above MA AND positive momentum\n",
    "pos_momentum = gt(price_momentum, 0)\n",
    "buy_signal = and_(above_ma, pos_momentum)\n",
    "print(\"Buy signal (above MA AND positive momentum):\")\n",
    "print(buy_signal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or_: Logical OR\n",
    "# Volatility signal: big move up OR big move down\n",
    "big_up = gt(daily_return, 0.02)    # > 2% return\n",
    "big_down = lt(daily_return, -0.02)  # < -2% return\n",
    "volatile = or_(big_up, big_down)\n",
    "print(\"Volatile day (|return| > 2%):\")\n",
    "print(volatile.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_: Logical NOT\n",
    "not_volatile = not_(volatile)\n",
    "print(\"Not volatile:\")\n",
    "print(not_volatile.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_nan: Detect NaN/null values\n",
    "has_nan = is_nan(daily_return)\n",
    "print(\"Is NaN (first row has NaN from delta):\")\n",
    "print(has_nan.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if_else: Conditional selection with scalar branches\n",
    "# Example: Cap large returns at +/-5%\n",
    "capped_return = if_else(\n",
    "    gt(daily_return, 0.05),  # condition\n",
    "    0.05,                     # then (scalar)\n",
    "    if_else(\n",
    "        lt(daily_return, -0.05),\n",
    "        -0.05,\n",
    "        daily_return           # else (DataFrame)\n",
    "    )\n",
    ")\n",
    "print(\"Capped returns (+/-5%):\")\n",
    "print(capped_return.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if_else with DataFrame branches\n",
    "# Example: Use momentum alpha when trend is up, mean-reversion when down\n",
    "momentum_alpha = rank(ts_delta(prices, 20))\n",
    "mean_rev_alpha = reverse(rank(ts_delta(prices, 5)))\n",
    "adaptive_alpha = if_else(above_ma, momentum_alpha, mean_rev_alpha)\n",
    "print(\"Adaptive alpha (trend-following when above MA, mean-reversion when below):\")\n",
    "print(adaptive_alpha.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Time-Series Operators (26 operators)\n",
    "\n",
    "Time-series operators work **column-wise** (down each column over time).\n",
    "\n",
    "**When to use:** Moving averages, momentum, volatility, trend signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "### 4.1 Basic Rolling (7 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `ts_mean` | Rolling mean |\n",
    "| `ts_sum` | Rolling sum |\n",
    "| `ts_std` | Rolling standard deviation |\n",
    "| `ts_min` | Rolling minimum |\n",
    "| `ts_max` | Rolling maximum |\n",
    "| `ts_delta` | Difference from d days ago |\n",
    "| `ts_delay` | Lag values by d days |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_mean: Moving average\n",
    "ma_20 = ts_mean(prices, 20)\n",
    "print(\"20-day moving average:\")\n",
    "print(ma_20.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_sum: Rolling sum (e.g., cumulative volume)\n",
    "vol_20d = ts_sum(volume, 20)\n",
    "print(\"20-day cumulative volume:\")\n",
    "print(vol_20d.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_std: Rolling volatility\n",
    "volatility = ts_std(daily_return, 20)\n",
    "print(\"20-day rolling volatility:\")\n",
    "print(volatility.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_min, ts_max: Rolling min/max (support/resistance)\n",
    "rolling_high = ts_max(prices, 20)\n",
    "rolling_low = ts_min(prices, 20)\n",
    "print(\"20-day high/low:\")\n",
    "print(rolling_high.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_delta: Price momentum (difference from d days ago)\n",
    "momentum_20d = ts_delta(prices, 20)\n",
    "print(\"20-day price change:\")\n",
    "print(momentum_20d.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_delay: Lagged values (for computing returns)\n",
    "prices_5d_ago = ts_delay(prices, 5)\n",
    "print(\"Prices 5 days ago:\")\n",
    "print(prices_5d_ago.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "### 4.2 Advanced Rolling (6 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `ts_product` | Rolling product |\n",
    "| `ts_count_nans` | Count nulls in window |\n",
    "| `ts_zscore` | Rolling z-score |\n",
    "| `ts_scale` | Rolling min-max scale |\n",
    "| `ts_av_diff` | Deviation from rolling mean |\n",
    "| `ts_step` | Row counter |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_product: Cumulative returns\n",
    "# First compute 1 + daily_return\n",
    "one_df = prices.select(pl.col(date_col), *[pl.lit(1.0).alias(c) for c in value_cols])\n",
    "return_factor = add(daily_return, one_df)\n",
    "cum_return = ts_product(return_factor, 5)\n",
    "print(\"5-day cumulative return factor:\")\n",
    "print(cum_return.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_count_nans: Count missing values in window\n",
    "nan_count = ts_count_nans(daily_return, 10)\n",
    "print(\"Count of NaN in 10-day window:\")\n",
    "print(nan_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_zscore: Rolling z-score (normalized deviation)\n",
    "price_zscore = ts_zscore(prices, 20)\n",
    "print(\"20-day rolling z-score:\")\n",
    "print(price_zscore.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_scale: Rolling min-max normalization [0, 1]\n",
    "scaled_price = ts_scale(prices, 20)\n",
    "print(\"20-day scaled price [0,1]:\")\n",
    "print(scaled_price.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_av_diff: Deviation from rolling mean\n",
    "price_dev = ts_av_diff(prices, 20)\n",
    "print(\"Deviation from 20-day mean:\")\n",
    "print(price_dev.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_step: Row counter (time index)\n",
    "time_idx = ts_step(prices)\n",
    "print(\"Row counter:\")\n",
    "print(time_idx.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-59",
   "metadata": {},
   "source": [
    "### 4.3 Arg and Lookback (6 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `ts_arg_max` | Days since window max |\n",
    "| `ts_arg_min` | Days since window min |\n",
    "| `ts_backfill` | Fill nulls with last valid |\n",
    "| `kth_element` | K-th element in lookback |\n",
    "| `last_diff_value` | Last different value |\n",
    "| `days_from_last_change` | Days since value changed |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_arg_max: Days since rolling high (0 = today is the high)\n",
    "days_since_high = ts_arg_max(prices, 20)\n",
    "print(\"Days since 20-day high:\")\n",
    "print(days_since_high.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_arg_min: Days since rolling low\n",
    "days_since_low = ts_arg_min(prices, 20)\n",
    "print(\"Days since 20-day low:\")\n",
    "print(days_since_low.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_backfill: Forward-fill NaN values\n",
    "sparse = daily_return.head(10)  # Has NaN in first row\n",
    "filled = ts_backfill(sparse, 5)\n",
    "print(\"Original (with NaN):\")\n",
    "print(sparse.head(3))\n",
    "print(\"After backfill:\")\n",
    "print(filled.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kth_element: Get k-th element in lookback window\n",
    "third_from_last = kth_element(prices, 5, 3)  # 3rd element in 5-day window\n",
    "print(\"3rd element in 5-day lookback:\")\n",
    "print(third_from_last.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_diff_value: Last value that was different\n",
    "discrete_signal = bucket(rank(prices), range_spec=\"0,1,0.25\")  # Discretize to buckets\n",
    "last_different = last_diff_value(discrete_signal, 10)\n",
    "print(\"Discrete signal:\")\n",
    "print(discrete_signal.head())\n",
    "print(\"Last different value:\")\n",
    "print(last_different.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_from_last_change: Days since value changed\n",
    "days_unchanged = days_from_last_change(discrete_signal)\n",
    "print(\"Days since signal changed:\")\n",
    "print(days_unchanged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-66",
   "metadata": {},
   "source": [
    "### 4.4 Stateful Operators (3 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `hump` | Limit change magnitude |\n",
    "| `ts_decay_linear` | Linear decay weighted average |\n",
    "| `ts_rank` | Percentile rank in window |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hump: Limit how much value can change between rows\n",
    "# Useful for smoothing signals and preventing whipsaws\n",
    "smooth_signal = hump(price_zscore, 0.5)  # Max change of 0.5 per period\n",
    "print(\"Original z-score:\")\n",
    "print(price_zscore.tail(3))\n",
    "print(\"Humped (smoothed) z-score:\")\n",
    "print(smooth_signal.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_decay_linear: Weighted average with linear decay (recent weighted more)\n",
    "# Weights: [1, 2, 3, ..., d] normalized\n",
    "decay_avg = ts_decay_linear(prices, 10)\n",
    "print(\"10-day linear decay weighted average:\")\n",
    "print(decay_avg.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_rank: Percentile rank of current value in rolling window\n",
    "# Returns 0-1 (1 = highest in window)\n",
    "percentile = ts_rank(prices, 20)\n",
    "print(\"Percentile rank in 20-day window:\")\n",
    "print(percentile.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-70",
   "metadata": {},
   "source": [
    "### 4.5 Two-Variable Operators (4 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `ts_corr` | Rolling correlation |\n",
    "| `ts_covariance` | Rolling covariance |\n",
    "| `ts_quantile` | Rank + inverse CDF transform |\n",
    "| `ts_regression` | Rolling OLS regression |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_corr: Rolling correlation between two DataFrames\n",
    "# Correlates matching columns (IBM price with IBM volume, etc.)\n",
    "price_vol_corr = ts_corr(prices, volume, 20)\n",
    "print(\"20-day rolling price-volume correlation:\")\n",
    "print(price_vol_corr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_covariance: Rolling covariance\n",
    "price_vol_cov = ts_covariance(prices, volume, 20)\n",
    "print(\"20-day rolling covariance:\")\n",
    "print(price_vol_cov.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_quantile: Transform rank to Gaussian via inverse CDF\n",
    "gaussian_rank = ts_quantile(prices, 20)\n",
    "print(\"Gaussian quantile transform:\")\n",
    "print(gaussian_rank.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_regression: Rolling OLS regression (y ~ x)\n",
    "# Returns beta coefficient by default\n",
    "beta = ts_regression(prices, volume, 20, rettype=\"beta\")\n",
    "print(\"20-day rolling beta (price vs volume):\")\n",
    "print(beta.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_regression with different return types\n",
    "alpha_reg = ts_regression(prices, volume, 20, rettype=\"alpha\")  # Intercept\n",
    "resid = ts_regression(prices, volume, 20, rettype=\"resid\")  # Residual (last)\n",
    "print(\"Regression alpha (intercept):\")\n",
    "print(alpha_reg.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-76",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Cross-Sectional Operators (6 operators)\n",
    "\n",
    "Cross-sectional operators work **row-wise** (across symbols at each date).\n",
    "\n",
    "**When to use:** Ranking stocks, standardizing across universe, portfolio construction.\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `rank` | Rank to [0, 1] across symbols |\n",
    "| `zscore` | Standardize (mean=0, std=1) |\n",
    "| `normalize` | Demean (subtract row mean) |\n",
    "| `scale` | Scale to target abs sum |\n",
    "| `quantile` | Rank + inverse CDF |\n",
    "| `winsorize` | Clip to mean +/- n*std |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank: Cross-sectional rank [0, 1]\n",
    "# rate parameter: 1.0 = standard, 2.0 = squared ranks (emphasize extremes)\n",
    "price_rank = rank(prices)\n",
    "print(\"Cross-sectional rank (highest price = 1.0):\")\n",
    "print(price_rank.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank with rate parameter\n",
    "rank_squared = rank(prices, rate=2.0)\n",
    "print(\"Squared rank (emphasizes extremes):\")\n",
    "print(rank_squared.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscore: Cross-sectional standardization\n",
    "cs_zscore = zscore(momentum_20d)\n",
    "print(\"Cross-sectional z-score of momentum:\")\n",
    "print(cs_zscore.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize: Demean (row sums to ~0)\n",
    "demeaned = normalize(momentum_20d)\n",
    "print(\"Demeaned momentum:\")\n",
    "print(demeaned.tail())\n",
    "# Verify row sums\n",
    "row_sums = demeaned.select(pl.sum_horizontal(pl.exclude(date_col))).to_series()\n",
    "print(f\"Row sums (should be ~0): {row_sums.tail(3).to_list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale: Scale to target absolute sum (for portfolio weights)\n",
    "# longscale/shortscale: separate scaling for long and short positions\n",
    "weights = scale(demeaned, scale=1.0)\n",
    "print(\"Portfolio weights (|sum| = 1):\")\n",
    "print(weights.tail())\n",
    "# Verify\n",
    "abs_sums = weights.select(pl.sum_horizontal(*[pl.col(c).abs() for c in value_cols])).to_series()\n",
    "print(f\"Abs sums (should be ~1): {abs_sums.tail(3).to_list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale with longscale/shortscale\n",
    "weights_asymmetric = scale(demeaned, longscale=0.6, shortscale=0.4)\n",
    "print(\"Asymmetric weights (60% long, 40% short):\")\n",
    "print(weights_asymmetric.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile: Rank + inverse CDF transform\n",
    "# driver: \"gaussian\" (default), \"uniform\", \"cauchy\"\n",
    "gaussian_quantile = quantile(momentum_20d, driver=\"gaussian\")\n",
    "print(\"Gaussian quantile transform:\")\n",
    "print(gaussian_quantile.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorize: Clip outliers to mean +/- n*std\n",
    "winsorized = winsorize(momentum_20d, std=2.0)\n",
    "print(\"Winsorized momentum (clipped to +/-2 std):\")\n",
    "print(winsorized.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-85",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Group Operators (6 operators)\n",
    "\n",
    "Group operators apply cross-sectional operations within defined groups (e.g., sectors).\n",
    "\n",
    "**When to use:** Sector-neutral alphas, industry-relative signals.\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `group_rank` | Rank within groups |\n",
    "| `group_zscore` | Z-score within groups |\n",
    "| `group_scale` | Min-max scale within groups |\n",
    "| `group_neutralize` | Subtract group mean |\n",
    "| `group_mean` | Weighted mean within groups |\n",
    "| `group_backfill` | Fill NaN with group mean |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sector groups\n",
    "# Tech: IBM, TXN, NOW, META\n",
    "# Healthcare: BMY, JNJ\n",
    "# Defense: LMT, GD\n",
    "# Utilities: SO, NEE\n",
    "sector_map = {\n",
    "    \"IBM\": 1, \"TXN\": 1, \"NOW\": 1, \"META\": 1,  # Tech\n",
    "    \"BMY\": 2, \"JNJ\": 2,                          # Healthcare\n",
    "    \"LMT\": 3, \"GD\": 3,                           # Defense\n",
    "    \"SO\": 4, \"NEE\": 4,                           # Utilities\n",
    "}\n",
    "\n",
    "# Create group DataFrame (same structure as prices)\n",
    "groups = prices.select(\n",
    "    pl.col(date_col),\n",
    "    *[pl.lit(sector_map.get(c, 0)).alias(c) for c in value_cols]\n",
    ")\n",
    "print(\"Sector groups:\")\n",
    "print(groups.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_rank: Rank within sector\n",
    "sector_rank = group_rank(momentum_20d, groups)\n",
    "print(\"Momentum rank within sector:\")\n",
    "print(sector_rank.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_zscore: Z-score within sector\n",
    "sector_zscore = group_zscore(momentum_20d, groups)\n",
    "print(\"Momentum z-score within sector:\")\n",
    "print(sector_zscore.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_scale: Min-max scale within sector [0, 1]\n",
    "sector_scaled = group_scale(momentum_20d, groups)\n",
    "print(\"Momentum scaled within sector:\")\n",
    "print(sector_scaled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_neutralize: Subtract sector mean (sector-neutral alpha)\n",
    "sector_neutral = group_neutralize(momentum_20d, groups)\n",
    "print(\"Sector-neutral momentum:\")\n",
    "print(sector_neutral.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_mean: Weighted mean within sector\n",
    "# Use market cap (approximated by price * volume) as weight\n",
    "market_cap_proxy = multiply(prices, volume)\n",
    "sector_avg = group_mean(momentum_20d, market_cap_proxy, groups)\n",
    "print(\"Market-cap weighted sector average momentum:\")\n",
    "print(sector_avg.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_backfill: Fill NaN with winsorized group mean\n",
    "print(\"group_backfill fills NaN values with the winsorized group mean\")\n",
    "print(\"Parameters: d=lookback window, std=winsorization threshold\")\n",
    "print(\"Example usage: group_backfill(sparse_data, groups, d=10, std=4.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-93",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Vector & Transformational Operators (4 operators)\n",
    "\n",
    "### 7.1 Vector Operators (2 operators)\n",
    "\n",
    "Work on list-type columns (arrays within cells).\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `vec_avg` | Mean of list elements |\n",
    "| `vec_sum` | Sum of list elements |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with list-type columns\n",
    "# Example: multiple analyst price targets per stock\n",
    "list_data = pl.DataFrame({\n",
    "    \"timestamp\": [date(2024, 1, 1), date(2024, 1, 2)],\n",
    "    \"IBM\": [[180.0, 185.0, 190.0], [182.0, 187.0]],\n",
    "    \"TXN\": [[200.0, 205.0], [210.0, 215.0, 220.0]],\n",
    "})\n",
    "print(\"Data with list columns:\")\n",
    "print(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_avg: Average of list elements\n",
    "avg_targets = vec_avg(list_data)\n",
    "print(\"Average of list elements:\")\n",
    "print(avg_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_sum: Sum of list elements\n",
    "sum_targets = vec_sum(list_data)\n",
    "print(\"Sum of list elements:\")\n",
    "print(sum_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-97",
   "metadata": {},
   "source": [
    "### 7.2 Transformational Operators (2 operators)\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `bucket` | Discretize to bucket indices |\n",
    "| `trade_when` | Stateful entry/exit logic |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket with range_spec: evenly spaced boundaries\n",
    "# range_spec=\"start,end,step\" -> boundaries at start, start+step, ..., end\n",
    "momentum_buckets = bucket(cs_zscore, range_spec=\"-2,2,0.5\")\n",
    "print(\"Momentum z-score buckets (boundaries at -2, -1.5, ..., 2):\")\n",
    "print(momentum_buckets.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket with explicit boundaries\n",
    "momentum_quintiles = bucket(cs_zscore, buckets=\"-1.5,-0.5,0.5,1.5\")\n",
    "print(\"Momentum quintiles:\")\n",
    "print(momentum_quintiles.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket with skipBegin/skipEnd: exclude edge buckets\n",
    "inner_buckets = bucket(cs_zscore, range_spec=\"-1,1,0.5\", skipBoth=True)\n",
    "print(\"Inner buckets only (skip extremes):\")\n",
    "print(inner_buckets.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket with NANGroup: assign NaN to separate bucket\n",
    "with_nan = bucket(daily_return, range_spec=\"-0.02,0.02,0.01\", NANGroup=True)\n",
    "print(\"Returns buckets with NANGroup:\")\n",
    "print(with_nan.head())  # First row has NaN -> gets special bucket index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trade_when: Stateful entry/exit trading logic\n",
    "# Entry when momentum z-score > 1, exit when < 0\n",
    "entry_trigger = gt(cs_zscore, 1.0)  # Boolean: enter when zscore > 1\n",
    "exit_trigger = lt(cs_zscore, 0.0)   # Boolean: exit when zscore < 0\n",
    "\n",
    "# Convert to numeric (trade_when expects > 0 as True)\n",
    "entry_numeric = if_else(entry_trigger, 1.0, 0.0)\n",
    "exit_numeric = if_else(exit_trigger, 1.0, 0.0)\n",
    "\n",
    "# Alpha to use when in position\n",
    "alpha_signal = cs_zscore\n",
    "\n",
    "# Stateful trading signal\n",
    "trade_signal = trade_when(entry_numeric, alpha_signal, exit_numeric)\n",
    "print(\"Trade signal (NaN = no position):\")\n",
    "print(trade_signal.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-103",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Alpha Factor Examples\n",
    "\n",
    "### 8.1 Momentum Alpha (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 20-day momentum factor with dollar-neutral weights\n",
    "# Step 1: Calculate returns\n",
    "price_20d_ago = ts_delay(prices, 20)\n",
    "momentum = divide(subtract(prices, price_20d_ago), price_20d_ago)\n",
    "\n",
    "# Step 2: Rank cross-sectionally\n",
    "momentum_ranked = rank(momentum)\n",
    "\n",
    "# Step 3: Z-score to center around 0\n",
    "alpha = zscore(momentum_ranked)\n",
    "\n",
    "# Step 4: Scale to dollar-neutral weights\n",
    "weights = scale(alpha, scale=1.0)\n",
    "\n",
    "print(\"Momentum alpha weights:\")\n",
    "print(weights.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dollar-neutrality\n",
    "last_row = weights.tail(1)\n",
    "weight_values = [last_row[c][0] for c in value_cols]\n",
    "print(f\"Sum of weights: {sum(w for w in weight_values if w is not None):.6f} (should be ~0)\")\n",
    "print(f\"Sum of |weights|: {sum(abs(w) for w in weight_values if w is not None):.6f} (should be ~1)\")\n",
    "print(f\"Long positions: {sum(1 for w in weight_values if w is not None and w > 0)}\")\n",
    "print(f\"Short positions: {sum(1 for w in weight_values if w is not None and w < 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-106",
   "metadata": {},
   "source": [
    "### 8.2 Combined Alpha (Multi-Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple signals:\n",
    "# 1. Price momentum (trend-following)\n",
    "# 2. Volume momentum (liquidity)\n",
    "# 3. Volatility-adjusted (risk-aware)\n",
    "\n",
    "# Signal 1: Price momentum (20-day)\n",
    "price_mom = rank(ts_delta(log_prices, 20))\n",
    "\n",
    "# Signal 2: Volume trend (positive = increasing interest)\n",
    "vol_trend = rank(ts_delta(volume, 20))\n",
    "\n",
    "# Signal 3: Inverse volatility (prefer stable stocks)\n",
    "inv_vol = rank(reverse(volatility))\n",
    "\n",
    "# Combine with equal weights\n",
    "combined_signal = add(price_mom, vol_trend, inv_vol)\n",
    "combined_alpha = zscore(combined_signal)\n",
    "combined_weights = scale(combined_alpha, scale=1.0)\n",
    "\n",
    "print(\"Combined multi-factor alpha weights:\")\n",
    "print(combined_weights.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector-neutral version\n",
    "sector_neutral_alpha = group_neutralize(combined_alpha, groups)\n",
    "sector_neutral_weights = scale(sector_neutral_alpha, scale=1.0)\n",
    "print(\"Sector-neutral combined alpha:\")\n",
    "print(sector_neutral_weights.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-109",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Caching & Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cache statistics\n",
    "stats = client.cache_stats()\n",
    "print(f\"Cached entries: {stats['entries']}\")\n",
    "print(f\"Cache size: {stats['total_size_bytes'] / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Location: {stats['cache_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "client.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-112",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: All 68 Operators\n",
    "\n",
    "### Time-Series (26)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `ts_mean(x, d)` | Rolling mean |\n",
    "| `ts_sum(x, d)` | Rolling sum |\n",
    "| `ts_std(x, d)` | Rolling std |\n",
    "| `ts_min(x, d)` | Rolling min |\n",
    "| `ts_max(x, d)` | Rolling max |\n",
    "| `ts_delta(x, d)` | Difference from d days ago |\n",
    "| `ts_delay(x, d)` | Lag by d days |\n",
    "| `ts_product(x, d)` | Rolling product |\n",
    "| `ts_count_nans(x, d)` | Count nulls in window |\n",
    "| `ts_zscore(x, d)` | Rolling z-score |\n",
    "| `ts_scale(x, d)` | Rolling min-max scale |\n",
    "| `ts_av_diff(x, d)` | Deviation from rolling mean |\n",
    "| `ts_step(x)` | Row counter |\n",
    "| `ts_arg_max(x, d)` | Days since window max |\n",
    "| `ts_arg_min(x, d)` | Days since window min |\n",
    "| `ts_backfill(x, d)` | Fill nulls with last valid |\n",
    "| `kth_element(x, d, k)` | k-th element in lookback |\n",
    "| `last_diff_value(x, d)` | Last different value |\n",
    "| `days_from_last_change(x)` | Days since value changed |\n",
    "| `hump(x, hump)` | Limit change magnitude |\n",
    "| `ts_decay_linear(x, d)` | Linear decay weighted avg |\n",
    "| `ts_rank(x, d)` | Percentile rank in window |\n",
    "| `ts_corr(x, y, d)` | Rolling correlation |\n",
    "| `ts_covariance(x, y, d)` | Rolling covariance |\n",
    "| `ts_quantile(x, d)` | Rank to Gaussian transform |\n",
    "| `ts_regression(y, x, d)` | Rolling OLS regression |\n",
    "\n",
    "### Cross-Sectional (6)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `rank(x)` | Rank to [0, 1] |\n",
    "| `zscore(x)` | Standardize (mean=0, std=1) |\n",
    "| `normalize(x)` | Demean |\n",
    "| `scale(x, scale)` | Scale to target abs sum |\n",
    "| `quantile(x)` | Rank + inverse CDF |\n",
    "| `winsorize(x, std)` | Clip to mean +/- n*std |\n",
    "\n",
    "### Arithmetic (15)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `abs(x)` | Absolute value |\n",
    "| `add(*args)` | Element-wise addition |\n",
    "| `subtract(x, y)` | Element-wise subtraction |\n",
    "| `multiply(*args)` | Element-wise multiplication |\n",
    "| `divide(x, y)` | Safe division |\n",
    "| `inverse(x)` | 1/x |\n",
    "| `log(x)` | Natural log |\n",
    "| `max(*args)` | Element-wise max |\n",
    "| `min(*args)` | Element-wise min |\n",
    "| `power(x, y)` | x^y |\n",
    "| `signed_power(x, y)` | sign(x) * \\|x\\|^y |\n",
    "| `sqrt(x)` | Square root |\n",
    "| `sign(x)` | Sign function |\n",
    "| `reverse(x)` | Negation |\n",
    "| `densify(x)` | Remap to 0..n-1 |\n",
    "\n",
    "### Logical (11)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `and_(x, y)` | Logical AND |\n",
    "| `or_(x, y)` | Logical OR |\n",
    "| `not_(x)` | Logical NOT |\n",
    "| `if_else(cond, then, else)` | Conditional |\n",
    "| `is_nan(x)` | Detect NaN |\n",
    "| `lt(x, y)` | Less than |\n",
    "| `le(x, y)` | Less than or equal |\n",
    "| `gt(x, y)` | Greater than |\n",
    "| `ge(x, y)` | Greater than or equal |\n",
    "| `eq(x, y)` | Equal |\n",
    "| `ne(x, y)` | Not equal |\n",
    "\n",
    "### Group (6)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `group_rank(x, g)` | Rank within groups |\n",
    "| `group_zscore(x, g)` | Z-score within groups |\n",
    "| `group_scale(x, g)` | Scale within groups |\n",
    "| `group_neutralize(x, g)` | Subtract group mean |\n",
    "| `group_mean(x, w, g)` | Weighted group mean |\n",
    "| `group_backfill(x, g, d)` | Fill NaN with group mean |\n",
    "\n",
    "### Vector (2)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `vec_avg(x)` | Mean of list elements |\n",
    "| `vec_sum(x)` | Sum of list elements |\n",
    "\n",
    "### Transformational (2)\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `bucket(x, ...)` | Discretize to buckets |\n",
    "| `trade_when(t, a, e)` | Stateful entry/exit |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
