{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantDL Tutorial\n",
    "\n",
    "A comprehensive guide to using QuantDL for alpha research.\n",
    "\n",
    "**Contents:**\n",
    "1. Setup & Configuration\n",
    "2. Security Resolution\n",
    "3. Daily Price Data\n",
    "4. Fundamentals & Metrics\n",
    "5. Time-Series Operators (26 operators)\n",
    "   - Basic: mean, sum, std, min, max, delta, delay\n",
    "   - Rolling: product, count_nans, zscore, scale, av_diff, step\n",
    "   - Arg: arg_max, arg_min\n",
    "   - Stateful: decay_linear, rank\n",
    "   - Two-variable: corr, covariance, quantile, regression\n",
    "6. Cross-Sectional Operators (6 operators)\n",
    "7. Alpha Factor Example\n",
    "8. Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantDL version: 0.1.1\n",
      "Client initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import quantdl\n",
    "from quantdl import QuantDLClient, SecurityInfo\n",
    "from quantdl.operators import (\n",
    "    # Time-series (basic)\n",
    "    ts_mean, ts_sum, ts_std, ts_min, ts_max, ts_delta, ts_delay,\n",
    "    # Time-series (rolling)\n",
    "    ts_product, ts_count_nans, ts_zscore, ts_scale, ts_av_diff, ts_step,\n",
    "    # Time-series (arg)\n",
    "    ts_arg_max, ts_arg_min,\n",
    "    # Time-series (lookback)\n",
    "    ts_backfill, kth_element, last_diff_value, days_from_last_change,\n",
    "    # Time-series (stateful)\n",
    "    hump, ts_decay_linear, ts_rank,\n",
    "    # Time-series (two-variable)\n",
    "    ts_corr, ts_covariance, ts_quantile, ts_regression,\n",
    "    # Cross-sectional\n",
    "    rank, zscore, normalize, scale, quantile, winsorize\n",
    ")\n",
    "import polars as pl\n",
    "from datetime import date\n",
    "\n",
    "# Initialize client\n",
    "client = QuantDLClient()\n",
    "print(f\"QuantDL version: {__import__('quantdl').__version__}\")\n",
    "print(\"Client initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal: Client Architecture\n",
    "\n",
    "```\n",
    "QuantDLClient\n",
    "     |\n",
    "     +---> S3StorageBackend ---> Polars scan_parquet() ---> S3 bucket\n",
    "     |          |\n",
    "     |          +---> storage_options (AWS credentials)\n",
    "     |\n",
    "     +---> DiskCache ---> ~/.quantdl/cache/\n",
    "     |          |\n",
    "     |          +---> metadata.json (LRU tracking)\n",
    "     |          +---> data/*.parquet (cached files)\n",
    "     |\n",
    "     +---> SecurityMaster ---> PIT symbol resolution\n",
    "```\n",
    "\n",
    "**Code references:**\n",
    "- `client.py:37-75` - Client initialization\n",
    "- `storage/s3.py:20-52` - S3 backend with Polars native integration\n",
    "- `storage/cache.py:28-57` - Cache initialization with LRU/TTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Security Resolution\n",
    "\n",
    "Resolve symbols, CIKs, or security IDs to `SecurityInfo` with point-in-time accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: AAPL\n",
      "Security ID: 4092\n",
      "Company: APPLE COMPUTER INC\n",
      "CIK: 0000320193\n",
      "CUSIP: 03783310\n",
      "PERMNO: 14593\n"
     ]
    }
   ],
   "source": [
    "# Resolve single symbol\n",
    "info = client.resolve(\"AAPL\")\n",
    "if info:\n",
    "    print(f\"Symbol: {info.symbol}\")\n",
    "    print(f\"Security ID: {info.security_id}\")\n",
    "    print(f\"Company: {info.company}\")\n",
    "    print(f\"CIK: {info.cik}\")\n",
    "    print(f\"CUSIP: {info.cusip}\")\n",
    "    print(f\"PERMNO: {info.permno}\")\n",
    "else:\n",
    "    print(\"AAPL not found in security master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SecurityInfo(AAPL, id=4092)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.resolve(\"AAPL\", as_of=date(2024, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved by CIK: AAPL\n"
     ]
    }
   ],
   "source": [
    "# Resolve by CIK (requires v0.1.1+ for int64 CIK columns)\n",
    "try:\n",
    "    by_cik = client.resolve(\"0000320193\")  # Apple's CIK\n",
    "    print(f\"Resolved by CIK: {by_cik.symbol if by_cik else 'Not found'}\")\n",
    "except Exception as e:\n",
    "    print(f\"CIK resolution error (update to v0.1.1+): {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 results:\n",
      "  AAPL: APPLE COMPUTER INC\n",
      "  AAPL: APPLE INC\n",
      "  MLP: MAUI LAND & PINEAPPLE CO INC\n",
      "  APLE: Apple Hospitality REIT, Inc.\n",
      "  PAPL: Pineapple Financial Inc.\n"
     ]
    }
   ],
   "source": [
    "# Search by partial name\n",
    "try:\n",
    "    results = client.security_master.search(\"Apple\", limit=5)\n",
    "    print(f\"Found {len(results)} results:\")\n",
    "    for r in results:\n",
    "        print(f\"  {r.symbol}: {r.company}\")\n",
    "except Exception as e:\n",
    "    print(f\"Search error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal: Point-in-Time Resolution\n",
    "\n",
    "```\n",
    "resolve(identifier, as_of)\n",
    "     |\n",
    "     +---> Load security_master.parquet (cached)\n",
    "     |\n",
    "     +---> Filter: start_date <= as_of AND (end_date IS NULL OR end_date >= as_of)\n",
    "     |\n",
    "     +---> Match identifier against: symbol, security_id, cik, cusip, permno\n",
    "     |          (v0.1.1+: cast to string for comparison)\n",
    "     |\n",
    "     +---> Return SecurityInfo or None\n",
    "```\n",
    "\n",
    "**Code references:**\n",
    "- `data/security_master.py:60-101` - resolve() with PIT filtering\n",
    "- `data/security_master.py:87-88` - Cast to Utf8 for type-safe comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Daily Price Data\n",
    "\n",
    "Fetch OHLCV data as wide tables (dates as rows, symbols as columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fetch daily data from S3\n",
    "try:\n",
    "    prices = client.daily(\n",
    "        [\"AAPL\", \"MSFT\", \"GOOGL\"],\n",
    "        field=\"close\",\n",
    "        start=\"2024-01-01\",\n",
    "        end=\"2024-03-31\"\n",
    "    )\n",
    "    print(f\"Fetched from S3: {prices.shape}\")\n",
    "    print(prices.head())\n",
    "    USE_MOCK_DATA = False\n",
    "except Exception as e:\n",
    "    print(f\"S3 data not available: {type(e).__name__}\")\n",
    "    print(\"Using mock data for operator examples...\")\n",
    "    USE_MOCK_DATA = True\n",
    "    \n",
    "    # Create mock price data\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    dates = pl.date_range(date(2024, 1, 1), date(2024, 3, 31), eager=True)\n",
    "    n = len(dates)\n",
    "    prices = pl.DataFrame({\n",
    "        \"timestamp\": dates,\n",
    "        \"AAPL\": [185.0 + sum(random.gauss(0.5, 2) for _ in range(i)) for i in range(n)],\n",
    "        \"MSFT\": [375.0 + sum(random.gauss(0.3, 1.5) for _ in range(i)) for i in range(n)],\n",
    "        \"GOOGL\": [140.0 + sum(random.gauss(0.2, 1.8) for _ in range(i)) for i in range(n)],\n",
    "    })\n",
    "    print(f\"Mock data shape: {prices.shape}\")\n",
    "    print(prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal: Daily Data Fetching\n",
    "\n",
    "```\n",
    "daily(symbols, field, start, end)\n",
    "     |\n",
    "     +---> Resolve symbols to security_ids via SecurityMaster\n",
    "     |\n",
    "     +---> Async parallel fetch (ThreadPoolExecutor, max_concurrency=10)\n",
    "     |          |\n",
    "     |          +---> For each security_id:\n",
    "     |                   +---> Check cache\n",
    "     |                   +---> If miss: S3 read data/raw/ticks/daily/{security_id}/history.parquet\n",
    "     |                   +---> Filter by date range\n",
    "     |\n",
    "     +---> Build wide table:\n",
    "     |          +---> Tag each df with symbol\n",
    "     |          +---> Concat all: (timestamp, symbol, value)\n",
    "     |          +---> Pivot: rows=timestamp, cols=symbol\n",
    "     |\n",
    "     +---> Sort by timestamp, return\n",
    "```\n",
    "\n",
    "**Code references:**\n",
    "- `client.py:167-235` - daily() method\n",
    "- `client.py:139-165` - Async parallel fetch\n",
    "- `client.py:107-137` - Single security fetch with caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Fundamentals & Metrics\n",
    "\n",
    "Fetch SEC filing fundamentals and derived metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamentals (requires data in S3)\n",
    "try:\n",
    "    revenue = client.fundamentals([\"AAPL\"], concept=\"Revenue\", start=\"2023-01-01\", end=\"2024-06-30\")\n",
    "    print(\"Revenue data:\")\n",
    "    print(revenue)\n",
    "except Exception as e:\n",
    "    print(f\"Fundamentals not available: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics (requires data in S3)\n",
    "try:\n",
    "    pe = client.metrics([\"AAPL\"], metric=\"pe_ratio\", start=\"2023-01-01\", end=\"2024-06-30\")\n",
    "    print(\"PE Ratio data:\")\n",
    "    print(pe)\n",
    "except Exception as e:\n",
    "    print(f\"Metrics not available: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal: Fundamentals/Metrics Fetching\n",
    "\n",
    "```\n",
    "fundamentals(symbols, concept, start, end)\n",
    "     |\n",
    "     +---> Resolve symbols to SecurityInfo (need CIK)\n",
    "     |\n",
    "     +---> Async parallel fetch by CIK:\n",
    "     |          +---> S3 read data/raw/fundamental/{cik}/fundamental.parquet\n",
    "     |\n",
    "     +---> Filter by concept, pivot to wide table\n",
    "\n",
    "metrics(symbols, metric, start, end)\n",
    "     |\n",
    "     +---> Same flow, but reads from:\n",
    "              data/derived/features/fundamental/{cik}/metrics.parquet\n",
    "```\n",
    "\n",
    "**Code references:**\n",
    "- `client.py:292-348` - fundamentals()\n",
    "- `client.py:404-458` - metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Time-Series Operators\n",
    "\n",
    "Column-wise operations applied over time (down each column).\n",
    "\n",
    "These operators work on wide DataFrames where:\n",
    "- First column = timestamp\n",
    "- Remaining columns = symbol values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Working with prices data: {prices.shape}\")\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_mean: Rolling mean (moving average)\n",
    "ma_20 = ts_mean(prices, 20)\n",
    "print(\"20-day moving average:\")\n",
    "print(ma_20.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_std: Rolling standard deviation (volatility)\n",
    "volatility = ts_std(prices, 20)\n",
    "print(\"20-day rolling std (volatility):\")\n",
    "print(volatility.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_delta: Difference (daily change)\n",
    "daily_change = ts_delta(prices, 1)\n",
    "print(\"1-day price change:\")\n",
    "print(daily_change.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_delay: Lag values (shift backward)\n",
    "lagged = ts_delay(prices, 5)\n",
    "print(\"Prices lagged by 5 days:\")\n",
    "print(lagged.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_min, ts_max: Rolling min/max\n",
    "rolling_high = ts_max(prices, 20)\n",
    "rolling_low = ts_min(prices, 20)\n",
    "print(\"20-day rolling high:\")\n",
    "print(rolling_high.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal: Time-Series Operators\n",
    "\n",
    "```\n",
    "ts_mean(df, window)\n",
    "     |\n",
    "     +---> Identify: date_col = columns[0], value_cols = columns[1:]\n",
    "     |\n",
    "     +---> For each value column:\n",
    "     |          +---> Apply pl.col(c).rolling_mean(window)\n",
    "     |\n",
    "     +---> Return df with same structure\n",
    "```\n",
    "\n",
    "| Operator | Polars Function |\n",
    "|----------|----------------|\n",
    "| `ts_mean` | `rolling_mean` |\n",
    "| `ts_sum` | `rolling_sum` |\n",
    "| `ts_std` | `rolling_std` |\n",
    "| `ts_min` | `rolling_min` |\n",
    "| `ts_max` | `rolling_max` |\n",
    "| `ts_delta` | `diff` |\n",
    "| `ts_delay` | `shift` |\n",
    "\n",
    "**Code references:**\n",
    "- `operators/time_series.py:10-85` - Basic TS operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Rolling Operators (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_product: Rolling product (useful for cumulative returns)\n",
    "product_5 = ts_product(prices, 5)\n",
    "print(\"5-day rolling product:\")\n",
    "print(product_5.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_zscore: Rolling z-score normalization\n",
    "rolling_zscore = ts_zscore(prices, 20)\n",
    "print(\"20-day rolling z-score:\")\n",
    "print(rolling_zscore.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_scale: Rolling min-max normalization (0 to 1 range)\n",
    "scaled = ts_scale(prices, 20)\n",
    "print(\"20-day rolling min-max scale:\")\n",
    "print(scaled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_av_diff: Deviation from rolling mean\n",
    "av_diff = ts_av_diff(prices, 20)\n",
    "print(\"Deviation from 20-day mean:\")\n",
    "print(av_diff.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_step: Row counter (useful for time tracking)\n",
    "step = ts_step(prices)\n",
    "print(\"Row counter:\")\n",
    "print(step.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Arg Operators (Find Position of Min/Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_arg_max/ts_arg_min: Days since max/min in window\n",
    "arg_max = ts_arg_max(prices, 20)\n",
    "arg_min = ts_arg_min(prices, 20)\n",
    "print(\"Days since 20-day high (0 = today is the high):\")\n",
    "print(arg_max.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Stateful Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_decay_linear: Linear decay weighted average (recent values weighted more)\n",
    "decay_avg = ts_decay_linear(prices, 10)\n",
    "print(\"10-day linear decay weighted average:\")\n",
    "print(decay_avg.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_rank: Percentile rank of current value within rolling window\n",
    "ts_percentile = ts_rank(prices, 20)\n",
    "print(\"Percentile rank in 20-day window (0-1):\")\n",
    "print(ts_percentile.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Two-Variable Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-variable operators take two wide tables (x and y) and correlate matching columns\n",
    "# Create a mock \"volume\" series to correlate with prices\n",
    "if USE_MOCK_DATA:\n",
    "    import random\n",
    "    random.seed(123)\n",
    "    volume = pl.DataFrame({\n",
    "        \"timestamp\": prices[\"timestamp\"],\n",
    "        **{col: [random.uniform(1e6, 5e6) for _ in range(len(prices))] for col in prices.columns[1:]}\n",
    "    })\n",
    "else:\n",
    "    volume = prices  # Just use prices as proxy if real data available\n",
    "\n",
    "# ts_corr: Rolling correlation between price and volume (per symbol)\n",
    "correlation = ts_corr(prices, volume, 20)\n",
    "print(\"20-day rolling correlation between price and volume:\")\n",
    "print(correlation.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Cross-Sectional Operators\n",
    "\n",
    "Row-wise operations applied across symbols (across each row at each date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank: Cross-sectional rank (0 to 1)\n",
    "ranked = rank(prices)\n",
    "print(\"Cross-sectional rank [0, 1]:\")\n",
    "print(ranked.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscore: Standardize across symbols (mean=0, std=1 per row)\n",
    "standardized = zscore(prices)\n",
    "print(\"Cross-sectional z-score:\")\n",
    "print(standardized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize: Subtract row mean (demean)\n",
    "demeaned = normalize(prices)\n",
    "print(\"Demeaned (each row sums to ~0):\")\n",
    "print(demeaned.head())\n",
    "\n",
    "# Verify: sum across columns should be ~0\n",
    "row_sums = demeaned.select(pl.sum_horizontal(pl.exclude(\"timestamp\"))).to_series()\n",
    "print(f\"\\nRow sums (should be ~0): {row_sums.head().to_list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale: Scale so |sum| = target (for dollar-neutral portfolios)\n",
    "weights = scale(demeaned, scale=1.0)\n",
    "print(\"Scaled weights (|sum| = 1):\")\n",
    "print(weights.head())\n",
    "\n",
    "# Verify: sum of absolute values should be ~1\n",
    "abs_sums = weights.select(pl.sum_horizontal(*[pl.col(c).abs() for c in weights.columns[1:]])).to_series()\n",
    "print(f\"\\nAbs sums (should be ~1): {abs_sums.head().to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal: Cross-Sectional Operators\n",
    "\n",
    "**rank():** Uses unpivot/pivot pattern\n",
    "```\n",
    "rank(df)\n",
    "     |\n",
    "     +---> Unpivot to long: (timestamp, symbol, value)\n",
    "     |\n",
    "     +---> Rank within each timestamp: pl.col(\"value\").rank().over(\"timestamp\")\n",
    "     |\n",
    "     +---> Pivot back to wide format\n",
    "```\n",
    "\n",
    "**zscore(), normalize(), scale():** Use horizontal operations\n",
    "```\n",
    "zscore(df)\n",
    "     |\n",
    "     +---> row_mean = pl.mean_horizontal(*value_cols)\n",
    "     |\n",
    "     +---> row_std = pl.concat_list(...).list.eval(pl.element().std())\n",
    "     |\n",
    "     +---> Transform: (value - mean) / std for each column\n",
    "```\n",
    "\n",
    "**Code references:**\n",
    "- `operators/cross_sectional.py:18-114` - rank()\n",
    "- `operators/cross_sectional.py:117-139` - zscore()\n",
    "- `operators/cross_sectional.py:215-261` - normalize()\n",
    "- `operators/cross_sectional.py:142-212` - scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Alpha Factor Example\n",
    "\n",
    "Build a simple **20-day momentum** factor and create **dollar-neutral portfolio weights**.\n",
    "\n",
    "### Strategy Concept\n",
    "Stocks that went up recently tend to continue going up (momentum effect).\n",
    "\n",
    "### Pipeline\n",
    "1. Calculate 20-day returns (momentum)\n",
    "2. Rank stocks by momentum cross-sectionally\n",
    "3. Convert ranks to z-scores (center around 0)\n",
    "4. Scale to dollar-neutral weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand to more symbols for better demonstration\n",
    "if USE_MOCK_DATA:\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    symbols = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"JPM\", \"V\", \"JNJ\"]\n",
    "    dates = pl.date_range(date(2024, 1, 1), date(2024, 6, 30), eager=True)\n",
    "    n = len(dates)\n",
    "    \n",
    "    data = {\"timestamp\": dates}\n",
    "    base_prices = {\"AAPL\": 185.0, \"MSFT\": 375.0, \"GOOGL\": 140.0, \"AMZN\": 150.0, \"NVDA\": 500.0,\n",
    "                   \"META\": 350.0, \"TSLA\": 250.0, \"JPM\": 170.0, \"V\": 275.0, \"JNJ\": 160.0}\n",
    "    for sym in symbols:\n",
    "        drift = random.uniform(-0.1, 0.5)  # Random drift\n",
    "        vol = random.uniform(1.0, 3.0)     # Random volatility\n",
    "        data[sym] = [base_prices[sym] + sum(random.gauss(drift, vol) for _ in range(i)) for i in range(n)]\n",
    "    \n",
    "    prices = pl.DataFrame(data)\n",
    "\n",
    "print(f\"Price data: {prices.shape}\")\n",
    "print(f\"Symbols: {prices.columns[1:]}\")\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate 20-day momentum (return)\n",
    "# Momentum = (price_today - price_20d_ago) / price_20d_ago\n",
    "\n",
    "price_20d_ago = ts_delay(prices, 20)\n",
    "value_cols = prices.columns[1:]\n",
    "\n",
    "# Calculate returns\n",
    "momentum_data = {\"timestamp\": prices[\"timestamp\"]}\n",
    "for col in value_cols:\n",
    "    momentum_data[col] = (prices[col] - price_20d_ago[col]) / price_20d_ago[col]\n",
    "momentum = pl.DataFrame(momentum_data)\n",
    "\n",
    "print(\"20-day momentum (returns):\")\n",
    "print(momentum.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Rank momentum cross-sectionally\n",
    "# Higher rank = higher momentum = we want to be long\n",
    "\n",
    "momentum_rank = rank(momentum)\n",
    "print(f\"Momentum ranks (0-1):\")\n",
    "print(momentum_rank.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert ranks to z-scores\n",
    "# This centers around 0 (some positive, some negative)\n",
    "\n",
    "alpha = zscore(momentum_rank)\n",
    "print(\"Alpha (z-scored ranks):\")\n",
    "print(alpha.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Scale to dollar-neutral weights\n",
    "# |sum of weights| = 1\n",
    "\n",
    "weights = scale(alpha, scale=1.0)\n",
    "print(\"Portfolio weights (positive=long, negative=short):\")\n",
    "print(weights.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dollar-neutrality\n",
    "last_row = weights.tail(1)\n",
    "weight_values = [last_row[col][0] for col in weights.columns[1:]]\n",
    "\n",
    "print(f\"Sum of weights: {sum(weight_values):.6f} (should be ~0)\")\n",
    "print(f\"Sum of |weights|: {sum(abs(w) for w in weight_values):.6f} (should be ~1)\")\n",
    "print(f\"\\nLong positions: {sum(1 for w in weight_values if w > 0)}\")\n",
    "print(f\"Short positions: {sum(1 for w in weight_values if w < 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Pipeline Summary\n",
    "\n",
    "```\n",
    "prices\n",
    "   |\n",
    "   +---> ts_delay(20) ---> price_20d_ago\n",
    "   |                            |\n",
    "   +------- (prices - price_20d_ago) / price_20d_ago -----> momentum\n",
    "                                                                |\n",
    "                                                           rank()\n",
    "                                                                |\n",
    "                                                           zscore()\n",
    "                                                                |\n",
    "                                                           scale(scale=1)\n",
    "                                                                |\n",
    "                                                           weights\n",
    "                                                    (dollar-neutral portfolio)\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Positive weight** = Long position (bet stock goes up)\n",
    "- **Negative weight** = Short position (bet stock goes down)\n",
    "- **Dollar-neutral** = Equal $ long and short (market-neutral, profit from relative performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Caching\n",
    "\n",
    "Monitor and manage the local disk cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cache statistics\n",
    "stats = client.cache_stats()\n",
    "print(f\"Cached entries: {stats['entries']}\")\n",
    "print(f\"Cache size: {stats['total_size_bytes'] / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Max size: {stats['max_size_bytes'] / 1024 / 1024 / 1024:.1f} GB\")\n",
    "print(f\"TTL: {stats['ttl_seconds'] / 3600:.1f} hours\")\n",
    "print(f\"Location: {stats['cache_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear cache if needed (uncomment to run)\n",
    "# client.clear_cache()\n",
    "# print(\"Cache cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Data APIs\n",
    "\n",
    "| API | Description | Returns |\n",
    "|-----|-------------|--------|\n",
    "| `client.resolve(id)` | Symbol/CIK/CUSIP lookup | `SecurityInfo` |\n",
    "| `client.daily(symbols, field)` | OHLCV prices | Wide DataFrame |\n",
    "| `client.fundamentals(symbols, concept)` | SEC fundamentals | Wide DataFrame |\n",
    "| `client.metrics(symbols, metric)` | Derived metrics | Wide DataFrame |\n",
    "\n",
    "### Time-Series Operators\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `ts_mean(x, d)` | Rolling mean |\n",
    "| `ts_sum(x, d)` | Rolling sum |\n",
    "| `ts_std(x, d)` | Rolling std |\n",
    "| `ts_min(x, d)` | Rolling min |\n",
    "| `ts_max(x, d)` | Rolling max |\n",
    "| `ts_delta(x, d)` | Difference from d days ago |\n",
    "| `ts_delay(x, d)` | Lag by d days |\n",
    "| `ts_product(x, d)` | Rolling product |\n",
    "| `ts_count_nans(x, d)` | Count nulls in window |\n",
    "| `ts_zscore(x, d)` | Rolling z-score |\n",
    "| `ts_scale(x, d)` | Rolling min-max scale |\n",
    "| `ts_av_diff(x, d)` | Deviation from rolling mean |\n",
    "| `ts_step(x)` | Row counter |\n",
    "| `ts_arg_max(x, d)` | Days since window max |\n",
    "| `ts_arg_min(x, d)` | Days since window min |\n",
    "| `ts_backfill(x, d)` | Fill nulls with last valid |\n",
    "| `kth_element(x, d, k)` | k-th element in lookback |\n",
    "| `last_diff_value(x, d)` | Last different value |\n",
    "| `days_from_last_change(x)` | Days since value changed |\n",
    "| `hump(x, hump)` | Limit change magnitude |\n",
    "| `ts_decay_linear(x, d)` | Linear decay weighted avg |\n",
    "| `ts_rank(x, d)` | Rank of current in window |\n",
    "| `ts_corr(x, y, d)` | Rolling correlation |\n",
    "| `ts_covariance(x, y, d)` | Rolling covariance |\n",
    "| `ts_quantile(x, d)` | Transform rank to Gaussian |\n",
    "| `ts_regression(y, x, d)` | Rolling OLS regression |\n",
    "\n",
    "### Cross-Sectional Operators\n",
    "\n",
    "| Operator | Description |\n",
    "|----------|-------------|\n",
    "| `rank(x)` | Rank to [0, 1] across symbols |\n",
    "| `zscore(x)` | Standardize (mean=0, std=1) |\n",
    "| `normalize(x)` | Demean (subtract row mean) |\n",
    "| `scale(x, scale)` | Scale to target abs sum |\n",
    "| `quantile(x)` | Rank + inverse CDF transform |\n",
    "| `winsorize(x, std)` | Clip to mean +/- std*SD |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "client.close()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
